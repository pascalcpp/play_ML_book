样本间的距离被一个字段所主导
![image.png](https://upload-images.jianshu.io/upload_images/7220971-ebf97e258f8fd29c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
![image.png](https://upload-images.jianshu.io/upload_images/7220971-5eb5b4c36252ce7f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

解决方案 ：将所有的数据映射到同一尺度

- #### 最值归一化 normalization：把所有数据映射到0-1之间
![image.png](https://upload-images.jianshu.io/upload_images/7220971-864763cd320c0c4d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
  1.将这个数据映射到0~Xmax-Xmin 之间
  2.然后对于每个x相比于整个范围所占的比例

适用于分布有明显边界的情况；受outlier影响较大



- #### 均值方差归一化 standardization
把所有数据归一到均值为0方差为1的分布中

适用于数据分布没有明显边界；有可能存在极端情况值
![image.png](https://upload-images.jianshu.io/upload_images/7220971-a24f17d1f06dcb87.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)


### 最值归一化 normalization


```python
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
```


```python
# 生成一个一维向量进行归一化
x = np.random.randint(0,100,size=100)
```


```python
x
```




    array([95,  6, 47, 89, 87, 86, 72, 46, 45, 42, 44, 68, 89, 28, 99, 10, 58,
           32, 96, 85, 69, 20, 84, 89,  6, 99, 74, 54,  6,  8, 66, 64, 52,  0,
            7, 55, 35, 20, 33, 28, 40, 92, 70, 49, 21, 16, 68, 76, 91, 68, 48,
           52, 19, 83, 34, 80, 15, 20, 60, 39, 56, 37, 27, 32, 12, 21, 54, 85,
           54, 43, 20, 86, 95, 81,  0, 18, 63, 40, 40, 70, 53, 77, 57, 64, 70,
           33,  9, 86, 72, 35, 97, 67, 55, 73, 99, 85, 94, 59, 80, 55])




```python
[(x-np.min(x))/np.max(x)-np.min(x)]
```




    [array([0.95959596, 0.06060606, 0.47474747, 0.8989899 , 0.87878788,
            0.86868687, 0.72727273, 0.46464646, 0.45454545, 0.42424242,
            0.44444444, 0.68686869, 0.8989899 , 0.28282828, 1.        ,
            0.1010101 , 0.58585859, 0.32323232, 0.96969697, 0.85858586,
            0.6969697 , 0.2020202 , 0.84848485, 0.8989899 , 0.06060606,
            1.        , 0.74747475, 0.54545455, 0.06060606, 0.08080808,
            0.66666667, 0.64646465, 0.52525253, 0.        , 0.07070707,
            0.55555556, 0.35353535, 0.2020202 , 0.33333333, 0.28282828,
            0.4040404 , 0.92929293, 0.70707071, 0.49494949, 0.21212121,
            0.16161616, 0.68686869, 0.76767677, 0.91919192, 0.68686869,
            0.48484848, 0.52525253, 0.19191919, 0.83838384, 0.34343434,
            0.80808081, 0.15151515, 0.2020202 , 0.60606061, 0.39393939,
            0.56565657, 0.37373737, 0.27272727, 0.32323232, 0.12121212,
            0.21212121, 0.54545455, 0.85858586, 0.54545455, 0.43434343,
            0.2020202 , 0.86868687, 0.95959596, 0.81818182, 0.        ,
            0.18181818, 0.63636364, 0.4040404 , 0.4040404 , 0.70707071,
            0.53535354, 0.77777778, 0.57575758, 0.64646465, 0.70707071,
            0.33333333, 0.09090909, 0.86868687, 0.72727273, 0.35353535,
            0.97979798, 0.67676768, 0.55555556, 0.73737374, 1.        ,
            0.85858586, 0.94949495, 0.5959596 , 0.80808081, 0.55555556])]




```python
# 生成一个二维矩阵进行归一化
X = np.random.randint(0,100,(50,2))
X[:10,:]
```




    array([[52,  2],
           [25, 93],
           [73, 31],
           [39, 48],
           [15, 57],
           [33, 42],
           [27, 15],
           [49, 48],
           [ 6, 62],
           [98, 82]])




```python
X = np.array(X,dtype=float)
```


```python
X[:10,:]
```




    array([[52.,  2.],
           [25., 93.],
           [73., 31.],
           [39., 48.],
           [15., 57.],
           [33., 42.],
           [27., 15.],
           [49., 48.],
           [ 6., 62.],
           [98., 82.]])




```python
X[:,0] = (X[:,0]-np.min(X[:,0]))/(np.max(X[:,0])-np.min(X[:,0]))
```


```python
X[:,1] = ((X[:,1]-np.min(X[:,1]))/(np.max(X[:,1])-np.min(X[:,1])))
```


```python
X[:10,:]
```




    array([[0.52525253, 0.02020202],
           [0.25252525, 0.93939394],
           [0.73737374, 0.31313131],
           [0.39393939, 0.48484848],
           [0.15151515, 0.57575758],
           [0.33333333, 0.42424242],
           [0.27272727, 0.15151515],
           [0.49494949, 0.48484848],
           [0.06060606, 0.62626263],
           [0.98989899, 0.82828283]])




```python
# 均值，可以看出现在的数据集是均匀分布的
np.mean(X[:,0])
```




    0.46848484848484845




```python
# 方差

z = X - u / sigma             z为标准正态分布
np.std(X[:,0])
```




    0.3156554505030807




```python
np.mean(X[:,1])
```




    0.4917171717171717




```python
np.std(X[:,1])
```




    0.2805277286657274



#### 均值方差归一化 Standardization


```python
X2 = np.random.randint(0,100,(50,2))
```


```python
X2 = np.array(X2,dtype=float)
```


```python
X2[:,0] = (X2[:,0]-np.mean(X2[:,0]))/np.std(X2[:,0])
```


```python
X2[:,1] = (X2[:,1]-np.mean(X2[:,1]))/np.std(X2[:,1])
```


```python
plt.scatter(X2[:,0],X2[:,1])
```




    <matplotlib.collections.PathCollection at 0x108c3d3c8>




![image.png](https://upload-images.jianshu.io/upload_images/7220971-0ab5834c8f32740f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)




```python
np.mean(X2[:,0])
```




    3.1086244689504386e-17




```python
np.std(X2[:,0])
```




    1.0




```python
np.mean(X2[:,1])
```




    1.7763568394002505e-17




```python
np.std(X2[:,1])
```




    1.0


## 对测试数据集如何归一化？
![1](https://upload-images.jianshu.io/upload_images/7220971-31777ce3f44b001c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

在scikit-learn中使用Scaler
![2](https://upload-images.jianshu.io/upload_images/7220971-1f6359864d8d23fc.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

### Scikit-learn 中的Scaler 


```python
import numpy as np
from sklearn import datasets
```


```python
iris = datasets.load_iris()
```


```python
X = iris.data
y = iris.target
```


```python
from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=666)
```

### scikit-learn 中的StandardScaler


```python
from sklearn.preprocessing import StandardScaler
```


```python
standardScaler = StandardScaler()
```


```python
# 存放了均值方差归一化所对应的信息
standardScaler.fit(X_train)
```




    StandardScaler(copy=True, with_mean=True, with_std=True)




```python
## 均值
standardScaler.mean_
```




    array([5.83416667, 3.0825    , 3.70916667, 1.16916667])




```python
## 描述数据的分布范围（标准差）
standardScaler.scale_
```




    array([0.81019502, 0.44076874, 1.76295187, 0.75429833])




```python
X_train = standardScaler.transform(X_train)
X_train
```




    array([[-0.90616043,  0.94720873, -1.30982967, -1.28485856],
           [-1.15301457, -0.18717298, -1.30982967, -1.28485856],
           [-0.16559799, -0.64092567,  0.22169257,  0.17345038],
           [ 0.45153738,  0.72033239,  0.95909217,  1.49918578],
           [-0.90616043, -1.3215547 , -0.40226093, -0.0916967 ],
           [ 1.43895396,  0.2665797 ,  0.56203085,  0.30602392],
           [ 0.3281103 , -1.09467835,  1.07253826,  0.30602392],
           [ 2.1795164 , -0.18717298,  1.63976872,  1.2340387 ],
           [-0.78273335,  2.30846679, -1.25310662, -1.4174321 ],
           [ 0.45153738, -2.00218372,  0.44858475,  0.43859746],
           [ 1.80923518, -0.41404933,  1.46959958,  0.83631808],
           [ 0.69839152,  0.2665797 ,  0.90236912,  1.49918578],
           [ 0.20468323,  0.72033239,  0.44858475,  0.571171  ],
           [-0.78273335, -0.86780201,  0.10824648,  0.30602392],
           [-0.53587921,  1.40096142, -1.25310662, -1.28485856],
           [-0.65930628,  1.40096142, -1.25310662, -1.28485856],
           [-1.0295875 ,  0.94720873, -1.19638358, -0.7545644 ],
           [-1.77014994, -0.41404933, -1.30982967, -1.28485856],
           [-0.04217092, -0.86780201,  0.10824648,  0.04087684],
           [-0.78273335,  0.72033239, -1.30982967, -1.28485856],
           [-1.52329579,  0.72033239, -1.30982967, -1.15228502],
           [ 0.82181859,  0.2665797 ,  0.78892303,  1.10146516],
           [-0.16559799, -0.41404933,  0.27841562,  0.17345038],
           [ 0.94524567, -0.18717298,  0.39186171,  0.30602392],
           [ 0.20468323, -0.41404933,  0.44858475,  0.43859746],
           [-1.39986872,  0.2665797 , -1.19638358, -1.28485856],
           [-1.15301457,  0.03970336, -1.25310662, -1.4174321 ],
           [ 1.06867274,  0.03970336,  1.07253826,  1.63175932],
           [ 0.57496445, -0.86780201,  0.67547694,  0.83631808],
           [ 0.3281103 , -0.64092567,  0.56203085,  0.04087684],
           [ 0.45153738, -0.64092567,  0.61875389,  0.83631808],
           [-0.16559799,  2.98909581, -1.25310662, -1.01971148],
           [ 0.57496445, -1.3215547 ,  0.67547694,  0.43859746],
           [ 0.69839152, -0.41404933,  0.33513866,  0.17345038],
           [-0.90616043,  1.62783776, -1.02621444, -1.01971148],
           [ 1.19209981, -0.64092567,  0.61875389,  0.30602392],
           [-0.90616043,  0.94720873, -1.30982967, -1.15228502],
           [-1.89357701, -0.18717298, -1.47999881, -1.4174321 ],
           [ 0.08125616, -0.18717298,  0.78892303,  0.83631808],
           [ 0.69839152, -0.64092567,  1.07253826,  1.2340387 ],
           [-0.28902506, -0.64092567,  0.67547694,  1.10146516],
           [-0.41245214, -1.54843104, -0.00519961, -0.22427024],
           [ 1.31552689,  0.03970336,  0.67547694,  0.43859746],
           [ 0.57496445,  0.72033239,  1.07253826,  1.63175932],
           [ 0.82181859, -0.18717298,  1.18598435,  1.36661224],
           [-0.16559799,  1.62783776, -1.13966053, -1.15228502],
           [ 0.94524567, -0.41404933,  0.5053078 ,  0.17345038],
           [ 1.06867274,  0.49345605,  1.12926131,  1.76433286],
           [-1.27644165, -0.18717298, -1.30982967, -1.4174321 ],
           [-1.0295875 ,  1.17408507, -1.30982967, -1.28485856],
           [ 0.20468323, -0.18717298,  0.61875389,  0.83631808],
           [-1.0295875 , -0.18717298, -1.19638358, -1.28485856],
           [ 0.3281103 , -0.18717298,  0.67547694,  0.83631808],
           [ 0.69839152,  0.03970336,  1.01581521,  0.83631808],
           [-0.90616043,  1.40096142, -1.25310662, -1.01971148],
           [-0.16559799, -0.18717298,  0.27841562,  0.04087684],
           [-1.0295875 ,  0.94720873, -1.36655271, -1.15228502],
           [-0.90616043,  1.62783776, -1.25310662, -1.15228502],
           [-1.52329579,  0.2665797 , -1.30982967, -1.28485856],
           [-0.53587921, -0.18717298,  0.44858475,  0.43859746],
           [ 0.82181859, -0.64092567,  0.5053078 ,  0.43859746],
           [ 0.3281103 , -0.64092567,  0.16496953,  0.17345038],
           [-1.27644165,  0.72033239, -1.19638358, -1.28485856],
           [-0.90616043,  0.49345605, -1.13966053, -0.88713794],
           [-0.04217092, -0.86780201,  0.78892303,  0.96889162],
           [-0.28902506, -0.18717298,  0.22169257,  0.17345038],
           [ 0.57496445, -0.64092567,  0.78892303,  0.43859746],
           [ 1.06867274,  0.49345605,  1.12926131,  1.2340387 ],
           [ 1.68580811, -0.18717298,  1.18598435,  0.571171  ],
           [ 1.06867274, -0.18717298,  0.84564608,  1.49918578],
           [-1.15301457,  0.03970336, -1.25310662, -1.4174321 ],
           [-1.15301457, -1.3215547 ,  0.44858475,  0.70374454],
           [-0.16559799, -1.3215547 ,  0.73219998,  1.10146516],
           [-1.15301457, -1.54843104, -0.2320918 , -0.22427024],
           [-0.41245214, -1.54843104,  0.05152343, -0.0916967 ],
           [ 1.06867274, -1.3215547 ,  1.18598435,  0.83631808],
           [ 0.82181859, -0.18717298,  1.01581521,  0.83631808],
           [-0.16559799, -1.09467835, -0.1186457 , -0.22427024],
           [ 0.20468323, -2.00218372,  0.73219998,  0.43859746],
           [ 1.06867274,  0.03970336,  0.56203085,  0.43859746],
           [-1.15301457,  0.03970336, -1.25310662, -1.4174321 ],
           [ 0.57496445, -1.3215547 ,  0.73219998,  0.96889162],
           [-1.39986872,  0.2665797 , -1.36655271, -1.28485856],
           [ 0.20468323, -0.86780201,  0.78892303,  0.571171  ],
           [-0.04217092, -1.09467835,  0.16496953,  0.04087684],
           [ 1.31552689,  0.2665797 ,  1.12926131,  1.49918578],
           [-1.77014994, -0.18717298, -1.36655271, -1.28485856],
           [ 1.56238103, -0.18717298,  1.2427074 ,  1.2340387 ],
           [ 1.19209981,  0.2665797 ,  1.2427074 ,  1.49918578],
           [-0.78273335,  0.94720873, -1.25310662, -1.28485856],
           [ 2.54979762,  1.62783776,  1.52632263,  1.10146516],
           [ 0.69839152, -0.64092567,  1.07253826,  1.36661224],
           [-0.28902506, -0.41404933, -0.06192266,  0.17345038],
           [-0.41245214,  2.53534313, -1.30982967, -1.28485856],
           [-1.27644165, -0.18717298, -1.30982967, -1.15228502],
           [ 0.57496445, -0.41404933,  1.07253826,  0.83631808],
           [-1.77014994,  0.2665797 , -1.36655271, -1.28485856],
           [-0.53587921,  1.8547141 , -1.13966053, -1.01971148],
           [-1.0295875 ,  0.72033239, -1.19638358, -1.01971148],
           [ 1.06867274, -0.18717298,  0.73219998,  0.70374454],
           [-0.53587921,  1.8547141 , -1.36655271, -1.01971148],
           [ 2.30294347, -0.64092567,  1.69649176,  1.10146516],
           [-0.28902506, -0.86780201,  0.27841562,  0.17345038],
           [ 1.19209981, -0.18717298,  1.01581521,  1.2340387 ],
           [-0.41245214,  0.94720873, -1.36655271, -1.28485856],
           [-1.27644165,  0.72033239, -1.02621444, -1.28485856],
           [-0.53587921,  0.72033239, -1.13966053, -1.28485856],
           [ 2.30294347,  1.62783776,  1.69649176,  1.36661224],
           [ 1.31552689,  0.03970336,  0.95909217,  1.2340387 ],
           [-0.28902506, -1.3215547 ,  0.10824648, -0.0916967 ],
           [-0.90616043,  0.72033239, -1.25310662, -1.28485856],
           [-0.90616043,  1.62783776, -1.19638358, -1.28485856],
           [ 0.3281103 , -0.41404933,  0.56203085,  0.30602392],
           [-0.04217092,  2.08159044, -1.42327576, -1.28485856],
           [-1.0295875 , -2.45593641, -0.1186457 , -0.22427024],
           [ 0.69839152,  0.2665797 ,  0.44858475,  0.43859746],
           [ 0.3281103 , -0.18717298,  0.5053078 ,  0.30602392],
           [ 0.08125616,  0.2665797 ,  0.61875389,  0.83631808],
           [ 0.20468323, -2.00218372,  0.16496953, -0.22427024],
           [ 1.93266225, -0.64092567,  1.35615349,  0.96889162]])




```python
X_test = standardScaler.transform(X_test)
X_test
```




    array([[-0.28902506, -0.18717298,  0.44858475,  0.43859746],
           [-0.04217092, -0.64092567,  0.78892303,  1.63175932],
           [-1.0295875 , -1.77530738, -0.2320918 , -0.22427024],
           [-0.04217092, -0.86780201,  0.78892303,  0.96889162],
           [-1.52329579,  0.03970336, -1.25310662, -1.28485856],
           [-0.41245214, -1.3215547 ,  0.16496953,  0.17345038],
           [-0.16559799, -0.64092567,  0.44858475,  0.17345038],
           [ 0.82181859, -0.18717298,  0.84564608,  1.10146516],
           [ 0.57496445, -1.77530738,  0.39186171,  0.17345038],
           [-0.41245214, -1.09467835,  0.39186171,  0.04087684],
           [ 1.06867274,  0.03970336,  0.39186171,  0.30602392],
           [-1.64672287, -1.77530738, -1.36655271, -1.15228502],
           [-1.27644165,  0.03970336, -1.19638358, -1.28485856],
           [-0.53587921,  0.72033239, -1.25310662, -1.01971148],
           [ 1.68580811,  1.17408507,  1.35615349,  1.76433286],
           [-0.04217092, -0.86780201,  0.22169257, -0.22427024],
           [-1.52329579,  1.17408507, -1.53672185, -1.28485856],
           [ 1.68580811,  0.2665797 ,  1.29943044,  0.83631808],
           [ 1.31552689,  0.03970336,  0.78892303,  1.49918578],
           [ 0.69839152, -0.86780201,  0.90236912,  0.96889162],
           [ 0.57496445,  0.49345605,  0.56203085,  0.571171  ],
           [-1.0295875 ,  0.72033239, -1.25310662, -1.28485856],
           [ 2.30294347, -1.09467835,  1.80993786,  1.49918578],
           [-1.0295875 ,  0.49345605, -1.30982967, -1.28485856],
           [ 0.45153738, -0.41404933,  0.33513866,  0.17345038],
           [ 0.08125616, -0.18717298,  0.27841562,  0.43859746],
           [-1.0295875 ,  0.2665797 , -1.42327576, -1.28485856],
           [-0.41245214, -1.77530738,  0.16496953,  0.17345038],
           [ 0.57496445,  0.49345605,  1.29943044,  1.76433286],
           [ 2.30294347, -0.18717298,  1.35615349,  1.49918578]])




```python
from sklearn.neighbors import KNeighborsClassifier
knn_clf = KNeighborsClassifier(n_neighbors=3)
```


```python
knn_clf.fit(X_train,y_train)
```




    KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
               metric_params=None, n_jobs=1, n_neighbors=3, p=2,
               weights='uniform')




```python
knn_clf.score(X_test,y_test)
```




    1.0


### 实现自己的StandardScaler
```
import numpy as np

class StandardScaler:

    def __init__(self):
        self.mean_ = None
        self.scale_ = None

    def fit(self, X):
        """根据测试数据集X获得数据的均值和方差"""
        assert X.ndim == 2, "The dimension of X must be 2"

        self.mean_ = np.array([np.mean(x[:i]) for i in range(X.shape(1))])
        self.scale_ = np.array([np.std(X[:i]) for i in range(X.shape(1))])

        return self


    def transform(self, X):
        """将X根据这个StandardScaler进行均值方差归一化处理"""
        assert X.ndim == 2, "The dimension of X must be 2"
        assert self.mean_ is not None and self.scale_ is not None,\
            "must fit before transform!"
        assert X.shape[1] == len(self.mean_), \
            "the feature number of X must be equal to mean_ and std_"

        resX = np.empty(shape=X.shape,dtype=float)
        for col in range(X.shape[1]):
            resX[:col] = (X[:col]-self.mean_[col]) / self.scale_[col]
        return resX
```
